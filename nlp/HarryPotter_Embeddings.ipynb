{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HarryPotter-Embeddings.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNyo/Rj9GRTZ5DdpXBGhDbV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cbadenes/notebooks/blob/main/nlp/HarryPotter_Embeddings.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OdMuoE4HIdus"
      },
      "outputs": [],
      "source": [
        "from urllib.request import urlopen\n",
        "\n",
        "def load_text(url):\n",
        "  print(\"loading text from:\",url,\"..\")\n",
        "  return urlopen(url)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "texts = [\n",
        "         \"https://bit.ly/01-stone\",\n",
        "         \"https://bit.ly/02-chamber\",\n",
        "         \"https://bit.ly/03-prisoner\",\n",
        "         \"https://bit.ly/04-fire\",\n",
        "         \"https://bit.ly/05-phoenix\",\n",
        "         \"https://bit.ly/06-prince\",\n",
        "         \"https://bit.ly/07-deathly\",\n",
        "]"
      ],
      "metadata": {
        "id": "j2QuaPKFrSqZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from spacy.lang.en import English\n",
        "\n",
        "#we disable all the annotators except the tokenizer so its fast\n",
        "nlp = English(disable=['tagger','parser','ner'])\n",
        "\n",
        "def tokenize(text):\n",
        "  return [token.text.lower() for token in nlp(text)]"
      ],
      "metadata": {
        "id": "ujW5lm3UsXJu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus_sentences = []\n",
        "for text in texts:\n",
        "  for line in load_text(text):\n",
        "    decoded_line = line.decode(\"utf-8\")\n",
        "    tokens = tokenize(decoded_line)\n",
        "    corpus_sentences.append(tokens)\n",
        "print(len(corpus_sentences),\"sentences\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s1nzjjdFtbjF",
        "outputId": "2842218e-741f-4bbc-c22e-34fdb838028a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading text from: https://bit.ly/01-stone ..\n",
            "loading text from: https://bit.ly/02-chamber ..\n",
            "loading text from: https://bit.ly/03-prisoner ..\n",
            "loading text from: https://bit.ly/04-fire ..\n",
            "loading text from: https://bit.ly/05-phoenix ..\n",
            "loading text from: https://bit.ly/06-prince ..\n",
            "loading text from: https://bit.ly/07-deathly ..\n",
            "211035 sentences\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import Word2Vec\n",
        "\n",
        "model = Word2Vec(sentences=corpus_sentences, size=100, window=5, min_count=1, workers=4)\n",
        "model.save(\"word2vec.model\")"
      ],
      "metadata": {
        "id": "cJXwo8ejujdJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w2vmodel = Word2Vec.load(\"word2vec.model\")\n",
        "word_vectors = w2vmodel.wv\n",
        "print(\"dimension of vectors:\",word_vectors.vector_size)\n",
        "print(\"number of vectors:\",len(word_vectors.index2word) )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "su0UYlVPxG_T",
        "outputId": "241c44e7-5863-4b3b-ce0a-a6465d90d506"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dimension of vectors: 100\n",
            "number of vectors: 23511\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_vectors.most_similar('harry')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BX8hutKuy6gp",
        "outputId": "41400d45-e18e-4bb7-9aaf-0634ebc51230"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('neville', 0.6940442323684692),\n",
              " ('snape', 0.6659226417541504),\n",
              " ('he', 0.6650320291519165),\n",
              " ('malfoy', 0.6603965163230896),\n",
              " ('cedric', 0.6530553698539734),\n",
              " ('cho', 0.6447467803955078),\n",
              " ('hagrid', 0.6433640718460083),\n",
              " ('krum', 0.6370573043823242),\n",
              " ('hermione', 0.631946325302124),\n",
              " ('dudley', 0.6276787519454956)]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_vectors.similarity('voldemort','harry')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M5uqJieX0vdh",
        "outputId": "da57836f-ae4c-4553-a227-09d7f5f78c81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5542105"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sim_snape=word_vectors.similarity('voldemort','snape')\n",
        "sim_dumbledore=word_vectors.similarity('voldemort','dumbledore')\n",
        "print(\"Similarity Voldemort-Snape:\", sim_snape)\n",
        "print(\"Similarity Voldemort-Dumbledore:\", sim_dumbledore)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UehmYe3D1Y4R",
        "outputId": "78e92111-fcd9-4b63-a13a-c50ec557cbfa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity Voldemort-Snape: 0.76479995\n",
            "Similarity Voldemort-Dumbledore: 0.8354391\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "s1 = tokenize('sirius black is a wizard')\n",
        "s2 = tokenize('the prisoner of azkaban')\n",
        "word_vectors.n_similarity(s1,s2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3gNzncql1dHo",
        "outputId": "c0089544-433b-4864-eb3f-149de06b80e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.19850536"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_vectors.most_similar_cosmul(positive=['ron','hermione'], negative=['harry'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6vv91Jjz5UHO",
        "outputId": "8a5b659d-b940-4277-ce6e-9e95c7218bb5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('ginny', 0.9963164329528809),\n",
              " ('luna', 0.9748616218566895),\n",
              " ('hagrid', 0.9652337431907654),\n",
              " ('neville', 0.9566739797592163),\n",
              " ('bill', 0.9371435642242432),\n",
              " ('percy', 0.9179114103317261),\n",
              " ('fred', 0.9101880788803101),\n",
              " ('george', 0.9000527858734131),\n",
              " ('lupin', 0.8895122408866882),\n",
              " ('dean', 0.8889251351356506)]"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_vectors.most_similar('aircraft')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        },
        "id": "-f7CqXD_6eOw",
        "outputId": "319c6173-0f9e-4355-bd0d-3b4730a158ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-39-c69f477d6400>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mword_vectors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmost_similar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'aircraft'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mmost_similar\u001b[0;34m(self, positive, negative, topn, restrict_vocab, indexer)\u001b[0m\n\u001b[1;32m    529\u001b[0m                 \u001b[0mmean\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 531\u001b[0;31m                 \u001b[0mmean\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_norm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    532\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m                     \u001b[0mall_words\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mword_vec\u001b[0;34m(self, word, use_norm)\u001b[0m\n\u001b[1;32m    450\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 452\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"word '%s' not in vocabulary\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: \"word 'aircraft' not in vocabulary\""
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import FastText\n",
        "model = FastText(sentences=corpus_sentences, size=100, window=5, min_count=1, workers=4)\n",
        "model.save(\"fasttext.model\")"
      ],
      "metadata": {
        "id": "5Sau80cB8YuX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ftmodel = FastText.load(\"fasttext.model\")\n",
        "ft_vectors = ftmodel.wv\n",
        "print(\"dimension of vectors:\",ft_vectors.vector_size)\n",
        "print(\"number of vectors:\",len(ft_vectors.index2word) )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9H_UJisb80lc",
        "outputId": "43867363-f59c-472c-fdbb-c0cb37022985"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dimension of vectors: 100\n",
            "number of vectors: 23511\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ft_vectors.most_similar('aircraft')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KPqCkxrK9tBe",
        "outputId": "c28fb611-301c-441f-efdc-8fc875429e46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('eeylops', 0.8819980025291443),\n",
              " ('uvula', 0.8461031317710876),\n",
              " ('emma', 0.8385815620422363),\n",
              " ('edgy', 0.8341172337532043),\n",
              " ('gulps', 0.8255451917648315),\n",
              " ('oops', 0.8202794790267944),\n",
              " ('symbols', 0.8183526992797852),\n",
              " ('oval', 0.8111798763275146),\n",
              " ('psychology', 0.8092900514602661),\n",
              " ('numerology', 0.8039298057556152)]"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ft_vectors.most_similar('harry')"
      ],
      "metadata": {
        "id": "b_gqJlqg-U8a",
        "outputId": "b93b7bd5-68b3-48a0-a698-9ea1d14b40cb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('harryv', 0.9873182773590088),\n",
              " ('harryy', 0.987255871295929),\n",
              " ('harry\\\\', 0.9871963262557983),\n",
              " ('harryl', 0.9871581792831421),\n",
              " ('harry-', 0.9865343570709229),\n",
              " ('harrys', 0.9843622446060181),\n",
              " ('harryâ€™d', 0.9617148637771606),\n",
              " ('lolharry', 0.9099390506744385),\n",
              " ('louharry', 0.906660258769989),\n",
              " ('loloharry', 0.9037372469902039)]"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    }
  ]
}
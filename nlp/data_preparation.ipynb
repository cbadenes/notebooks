{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cbadenes/notebooks/blob/main/nlp/data_preparation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "61e42b47",
      "metadata": {
        "id": "61e42b47"
      },
      "source": [
        "# Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cc3e3689",
      "metadata": {
        "id": "cc3e3689"
      },
      "outputs": [],
      "source": [
        "# Original text with emojis\n",
        "original_text = \"\"\"\n",
        "Yesterday, I couldn't believe my eyes:\n",
        "I saw a man carrying a bunch of colorful balloons üéàüéà flying\n",
        "over the city! It was like something out of a fairy tale.\n",
        "Later, I read in the news that he's a scientist\n",
        "who's experimenting with new forms of transportation.\n",
        "His 'flying' experiment was part of a larger study.\n",
        "I hope it goes well; it's such a unique idea! üòä\n",
        "\"\"\".replace('\\n', ' ')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "99512bda",
      "metadata": {
        "id": "99512bda"
      },
      "source": [
        "## Step 0: Parse Text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3fdfbc6d",
      "metadata": {
        "id": "3fdfbc6d",
        "outputId": "22fee47f-192f-4d5b-b48f-bac6926630bc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: emoji in /Users/cbadenes/miniforge3/lib/python3.9/site-packages (2.10.0)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.2\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install emoji"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "debb6d7f",
      "metadata": {
        "id": "debb6d7f",
        "outputId": "501ab65f-0c3b-453f-a502-97737e1b0122"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Yesterday, I couldn't believe my eyes:  I saw a man carrying a bunch of colorful balloons :balloon::balloon: flying  over the city! It was like something out of a fairy tale.  Later, I read in the news that he's a scientist  who's experimenting with new forms of transportation.  His 'flying' experiment was part of a larger study.  I hope it goes well; it's such a unique idea! :smiling_face_with_smiling_eyes: \n"
          ]
        }
      ],
      "source": [
        "import emoji\n",
        "\n",
        "# Convert emojis to their text description\n",
        "parsed_text = emoji.demojize(original_text)\n",
        "\n",
        "print(parsed_text)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "72e9253b",
      "metadata": {
        "id": "72e9253b"
      },
      "source": [
        "## Step 1: Remove Special Characters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6bb36308",
      "metadata": {
        "id": "6bb36308",
        "outputId": "f4681153-4382-45c3-bf3f-fa83c0e2c5b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: regex in /Users/cbadenes/miniforge3/lib/python3.9/site-packages (2022.1.18)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.2\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install regex"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "86c3778c",
      "metadata": {
        "id": "86c3778c",
        "outputId": "a65b6763-1f67-4e0d-b9db-0f55ebee8ec6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Yesterday, I couldn't believe my eyes:  I saw a man carrying a bunch of colorful balloons  flying  over the city! It was like something out of a fairy tale.  Later, I read in the news that he's a scientist  who's experimenting with new forms of transportation.  His 'flying' experiment was part of a larger study.  I hope it goes well; it's such a unique idea!  \n"
          ]
        }
      ],
      "source": [
        "# Import the regex module\n",
        "import re\n",
        "\n",
        "# Emojis are encoded as :text: so we can remove them using a regex pattern\n",
        "emoji_pattern = re.compile(\":[a-zA-Z_]+:\")\n",
        "step1_text = emoji_pattern.sub(\"\", parsed_text)\n",
        "print(step1_text)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a4b10601",
      "metadata": {
        "id": "a4b10601"
      },
      "source": [
        "## Step 2: Handle Contractions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fa9ceedc",
      "metadata": {
        "id": "fa9ceedc",
        "outputId": "c316aff3-4df8-42c0-8a91-fdb8f7eba7cc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Yesterday, I could not believe my eyes:  I saw a man carrying a bunch of colorful balloons  flying  over the city! It was like something out of a fairy tale.  Later, I read in the news that he is a scientist  who is experimenting with new forms of transportation.  His 'flying' experiment was part of a larger study.  I hope it goes well; it is such a unique idea!  \n"
          ]
        }
      ],
      "source": [
        "# Expand Contractions\n",
        "# For this example, we'll manually define a dictionary of contractions and their expansions\n",
        "\n",
        "contractions_dict = {\n",
        "    \"couldn't\": \"could not\",\n",
        "    \"he's\": \"he is\",\n",
        "    \"who's\": \"who is\",\n",
        "    \"it's\": \"it is\",\n",
        "}\n",
        "\n",
        "step2_text = step1_text\n",
        "for contraction, expanded in contractions_dict.items():\n",
        "    step2_text = step2_text.replace(contraction, expanded)\n",
        "print(step2_text)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "22bb5e58",
      "metadata": {
        "id": "22bb5e58"
      },
      "source": [
        "## Step 3: Punctuation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5bec31c5",
      "metadata": {
        "id": "5bec31c5",
        "outputId": "8d630f5e-2898-4725-c93b-0707d60c11d4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Yesterday I could not believe my eyes  I saw a man carrying a bunch of colorful balloons  flying  over the city It was like something out of a fairy tale  Later I read in the news that he is a scientist  who is experimenting with new forms of transportation  His 'flying' experiment was part of a larger study  I hope it goes well it is such a unique idea  \n"
          ]
        }
      ],
      "source": [
        "# Remove Punctuation\n",
        "# We can use regex to remove any characters that are not alphanumeric (letters and numbers)\n",
        "\n",
        "step3_text = re.sub(r'[^\\w\\s\\']', '', step2_text)\n",
        "print(step3_text)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9cdb2e36",
      "metadata": {
        "id": "9cdb2e36"
      },
      "source": [
        "## Step 4: Lowercasing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e36d4de2",
      "metadata": {
        "id": "e36d4de2",
        "outputId": "6c56cfd3-e962-4500-d07f-34220b4fe6be"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " yesterday i could not believe my eyes  i saw a man carrying a bunch of colorful balloons  flying  over the city it was like something out of a fairy tale  later i read in the news that he is a scientist  who is experimenting with new forms of transportation  his 'flying' experiment was part of a larger study  i hope it goes well it is such a unique idea  \n"
          ]
        }
      ],
      "source": [
        "# Convert to Lowercase\n",
        "# Python's string method .lower() will convert all characters to lowercase\n",
        "\n",
        "step4_text = step3_text.lower()\n",
        "print(step4_text)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "61c6c582",
      "metadata": {
        "id": "61c6c582"
      },
      "source": [
        "## Step 5: Handle Quotation Marks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "87fbaa1c",
      "metadata": {
        "id": "87fbaa1c",
        "outputId": "833b5778-cb20-43f1-b678-51de8db622db"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " yesterday i could not believe my eyes  i saw a man carrying a bunch of colorful balloons  flying  over the city it was like something out of a fairy tale  later i read in the news that he is a scientist  who is experimenting with new forms of transportation  his flying experiment was part of a larger study  i hope it goes well it is such a unique idea  \n"
          ]
        }
      ],
      "source": [
        "# Remove Quotation Marks\n",
        "# If there were any quotation marks left, we would remove them here\n",
        "\n",
        "step5_text = re.sub(r'[\\'\\\"]', '', step4_text)\n",
        "print(step5_text)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9a5f2829",
      "metadata": {
        "id": "9a5f2829"
      },
      "source": [
        "## Step 6: Whitespace Normalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b25e7082",
      "metadata": {
        "id": "b25e7082",
        "outputId": "be79eede-8b96-4b90-e81f-061aadc8f2e4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "yesterday i could not believe my eyes i saw a man carrying a bunch of colorful balloons flying over the city it was like something out of a fairy tale later i read in the news that he is a scientist who is experimenting with new forms of transportation his flying experiment was part of a larger study i hope it goes well it is such a unique idea\n"
          ]
        }
      ],
      "source": [
        "# Normalize Whitespace\n",
        "# We can use regex to replace any series of whitespace characters with a single space\n",
        "\n",
        "step6_text = re.sub(r'\\s+', ' ', step5_text).strip()\n",
        "print(step6_text)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eac494ff",
      "metadata": {
        "id": "eac494ff"
      },
      "source": [
        "## Step 7: Tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "00722a4a",
      "metadata": {
        "id": "00722a4a",
        "outputId": "19e702fa-30ec-4f2a-905a-7603878c0ad9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nltk in /Users/cbadenes/miniforge3/lib/python3.9/site-packages (3.6.7)\n",
            "Requirement already satisfied: click in /Users/cbadenes/miniforge3/lib/python3.9/site-packages (from nltk) (7.1.2)\n",
            "Requirement already satisfied: joblib in /Users/cbadenes/miniforge3/lib/python3.9/site-packages (from nltk) (1.2.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /Users/cbadenes/miniforge3/lib/python3.9/site-packages (from nltk) (2022.1.18)\n",
            "Requirement already satisfied: tqdm in /Users/cbadenes/miniforge3/lib/python3.9/site-packages (from nltk) (4.65.0)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.2\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2145865c",
      "metadata": {
        "id": "2145865c",
        "outputId": "a4a01f07-22cc-4e03-bd82-11f55e92defa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['yesterday', 'i', 'could', 'not', 'believe', 'my', 'eyes', 'i', 'saw', 'a', 'man', 'carrying', 'a', 'bunch', 'of', 'colorful', 'balloons', 'flying', 'over', 'the', 'city', 'it', 'was', 'like', 'something', 'out', 'of', 'a', 'fairy', 'tale', 'later', 'i', 'read', 'in', 'the', 'news', 'that', 'he', 'is', 'a', 'scientist', 'who', 'is', 'experimenting', 'with', 'new', 'forms', 'of', 'transportation', 'his', 'flying', 'experiment', 'was', 'part', 'of', 'a', 'larger', 'study', 'i', 'hope', 'it', 'goes', 'well', 'it', 'is', 'such', 'a', 'unique', 'idea']\n"
          ]
        }
      ],
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "tokens = word_tokenize(step6_text)\n",
        "print(tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2d57c40e",
      "metadata": {
        "id": "2d57c40e"
      },
      "source": [
        "## Step 8a: Stemming"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bc25a17a",
      "metadata": {
        "id": "bc25a17a",
        "outputId": "8516dde3-d44c-4fca-c9ed-f3eb9c0c8b75"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['yesterday', 'i', 'could', 'not', 'believ', 'my', 'eye', 'i', 'saw', 'a', 'man', 'carri', 'a', 'bunch', 'of', 'color', 'balloon', 'fli', 'over', 'the', 'citi', 'it', 'wa', 'like', 'someth', 'out', 'of', 'a', 'fairi', 'tale', 'later', 'i', 'read', 'in', 'the', 'news', 'that', 'he', 'is', 'a', 'scientist', 'who', 'is', 'experi', 'with', 'new', 'form', 'of', 'transport', 'hi', 'fli', 'experi', 'wa', 'part', 'of', 'a', 'larger', 'studi', 'i', 'hope', 'it', 'goe', 'well', 'it', 'is', 'such', 'a', 'uniqu', 'idea']\n"
          ]
        }
      ],
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "stemmer = PorterStemmer()\n",
        "stemmed_tokens = [stemmer.stem(token) for token in tokens]\n",
        "print(stemmed_tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1cec9ad8",
      "metadata": {
        "id": "1cec9ad8"
      },
      "source": [
        "## Step 8b: Lemmatization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b083a7c2",
      "metadata": {
        "scrolled": false,
        "id": "b083a7c2",
        "outputId": "563ada9d-ef57-493b-932a-2e0f2ed5c488"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: spacy in /Users/cbadenes/miniforge3/lib/python3.9/site-packages (3.5.3)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /Users/cbadenes/miniforge3/lib/python3.9/site-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /Users/cbadenes/miniforge3/lib/python3.9/site-packages (from spacy) (1.0.1)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/cbadenes/miniforge3/lib/python3.9/site-packages (from spacy) (1.0.6)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/cbadenes/miniforge3/lib/python3.9/site-packages (from spacy) (2.0.6)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/cbadenes/miniforge3/lib/python3.9/site-packages (from spacy) (3.0.6)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /Users/cbadenes/miniforge3/lib/python3.9/site-packages (from spacy) (8.1.10)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /Users/cbadenes/miniforge3/lib/python3.9/site-packages (from spacy) (0.10.1)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /Users/cbadenes/miniforge3/lib/python3.9/site-packages (from spacy) (2.4.5)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /Users/cbadenes/miniforge3/lib/python3.9/site-packages (from spacy) (2.0.6)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /Users/cbadenes/miniforge3/lib/python3.9/site-packages (from spacy) (0.3.2)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /Users/cbadenes/miniforge3/lib/python3.9/site-packages (from spacy) (0.10.1)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /Users/cbadenes/miniforge3/lib/python3.9/site-packages (from spacy) (5.2.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Users/cbadenes/miniforge3/lib/python3.9/site-packages (from spacy) (4.65.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /Users/cbadenes/miniforge3/lib/python3.9/site-packages (from spacy) (1.24.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/cbadenes/miniforge3/lib/python3.9/site-packages (from spacy) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /Users/cbadenes/miniforge3/lib/python3.9/site-packages (from spacy) (1.10.9)\n",
            "Requirement already satisfied: jinja2 in /Users/cbadenes/miniforge3/lib/python3.9/site-packages (from spacy) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /Users/cbadenes/miniforge3/lib/python3.9/site-packages (from spacy) (59.8.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /Users/cbadenes/miniforge3/lib/python3.9/site-packages (from spacy) (23.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /Users/cbadenes/miniforge3/lib/python3.9/site-packages (from spacy) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /Users/cbadenes/miniforge3/lib/python3.9/site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy) (4.6.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/cbadenes/miniforge3/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.1.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Users/cbadenes/miniforge3/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/cbadenes/miniforge3/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Users/cbadenes/miniforge3/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2023.5.7)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /Users/cbadenes/miniforge3/lib/python3.9/site-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.7.9)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /Users/cbadenes/miniforge3/lib/python3.9/site-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.0.3)\n",
            "Requirement already satisfied: click<7.2.0,>=7.1.1 in /Users/cbadenes/miniforge3/lib/python3.9/site-packages (from typer<0.8.0,>=0.3.0->spacy) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /Users/cbadenes/miniforge3/lib/python3.9/site-packages (from jinja2->spacy) (2.1.3)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.2\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
            "Collecting en-core-web-sm==3.5.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.5.0/en_core_web_sm-3.5.0-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[38;2;114;156;31m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m33.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m01\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.6.0,>=3.5.0 in /Users/cbadenes/miniforge3/lib/python3.9/site-packages (from en-core-web-sm==3.5.0) (3.5.3)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /Users/cbadenes/miniforge3/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /Users/cbadenes/miniforge3/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.0.1)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/cbadenes/miniforge3/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.0.6)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/cbadenes/miniforge3/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.6)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/cbadenes/miniforge3/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.0.6)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /Users/cbadenes/miniforge3/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (8.1.10)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /Users/cbadenes/miniforge3/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.10.1)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /Users/cbadenes/miniforge3/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.4.5)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /Users/cbadenes/miniforge3/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.6)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /Users/cbadenes/miniforge3/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.3.2)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /Users/cbadenes/miniforge3/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.10.1)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /Users/cbadenes/miniforge3/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (5.2.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Users/cbadenes/miniforge3/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (4.65.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /Users/cbadenes/miniforge3/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.24.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/cbadenes/miniforge3/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /Users/cbadenes/miniforge3/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.10.9)\n",
            "Requirement already satisfied: jinja2 in /Users/cbadenes/miniforge3/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /Users/cbadenes/miniforge3/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (59.8.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /Users/cbadenes/miniforge3/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (23.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /Users/cbadenes/miniforge3/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /Users/cbadenes/miniforge3/lib/python3.9/site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (4.6.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/cbadenes/miniforge3/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.1.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Users/cbadenes/miniforge3/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/cbadenes/miniforge3/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Users/cbadenes/miniforge3/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2023.5.7)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /Users/cbadenes/miniforge3/lib/python3.9/site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.7.9)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /Users/cbadenes/miniforge3/lib/python3.9/site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.0.3)\n",
            "Requirement already satisfied: click<7.2.0,>=7.1.1 in /Users/cbadenes/miniforge3/lib/python3.9/site-packages (from typer<0.8.0,>=0.3.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /Users/cbadenes/miniforge3/lib/python3.9/site-packages (from jinja2->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.1.3)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.2\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
            "\u001b[38;5;2m‚úî Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n"
          ]
        }
      ],
      "source": [
        "!pip install spacy\n",
        "!python -m spacy download en_core_web_sm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2f7d5a52",
      "metadata": {
        "id": "2f7d5a52",
        "outputId": "a71b22db-da5c-43ea-99da-d5c105c624b4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['yesterday', 'I', 'could', 'not', 'believe', 'my', 'eye', 'I', 'see', 'a', 'man', 'carry', 'a', 'bunch', 'of', 'colorful', 'balloon', 'fly', 'over', 'the', 'city', 'it', 'be', 'like', 'something', 'out', 'of', 'a', 'fairy', 'tale', 'later', 'I', 'read', 'in', 'the', 'news', 'that', 'he', 'be', 'a', 'scientist', 'who', 'be', 'experiment', 'with', 'new', 'form', 'of', 'transportation', 'his', 'fly', 'experiment', 'be', 'part', 'of', 'a', 'large', 'study', 'I', 'hope', 'it', 'go', 'well', 'it', 'be', 'such', 'a', 'unique', 'idea']\n"
          ]
        }
      ],
      "source": [
        "import spacy\n",
        "\n",
        "# Load the Spacy model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Process the text\n",
        "doc = nlp(step6_text)\n",
        "\n",
        "# Tokenization and Lemmatization\n",
        "lemmatized_tokens = [token.lemma_ for token in doc]\n",
        "\n",
        "# Printing lemmatized tokens\n",
        "print(lemmatized_tokens)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "66437ac7",
      "metadata": {
        "id": "66437ac7"
      },
      "source": [
        "## Step 9: Removal of Stopwords"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5a8f39ad",
      "metadata": {
        "id": "5a8f39ad",
        "outputId": "2f02e07f-97df-49db-94cf-ba7163e3ec25"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['yesterday', 'believe', 'eye', 'see', 'man', 'carry', 'bunch', 'colorful', 'balloon', 'fly', 'city', 'like', 'fairy', 'tale', 'later', 'read', 'news', 'scientist', 'experiment', 'new', 'form', 'transportation', 'fly', 'experiment', 'large', 'study', 'hope', 'go', 'unique', 'idea']\n"
          ]
        }
      ],
      "source": [
        "# Generate a list of lemmatized tokens that are not stopwords and not punctuation\n",
        "filtered_tokens = [token.lemma_ for token in doc if not token.is_stop and not token.is_punct]\n",
        "\n",
        "# Print the non-stopwords tokens\n",
        "print(filtered_tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "99a065a2",
      "metadata": {
        "id": "99a065a2"
      },
      "source": [
        "# Analysing and Modeling"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c1bdcd85",
      "metadata": {
        "id": "c1bdcd85"
      },
      "source": [
        "## BoW"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "75ce1aee",
      "metadata": {
        "scrolled": true,
        "id": "75ce1aee"
      },
      "outputs": [],
      "source": [
        "!pip install sklearn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f3187de9",
      "metadata": {
        "id": "f3187de9",
        "outputId": "e0ed1cb4-70dc-4614-b3e8-8653b6438a77"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]]\n",
            "['balloons' 'believe' 'bunch' 'carrying' 'city' 'colorful' 'couldn'\n",
            " 'experiment' 'experimenting' 'eyes' 'fairy' 'flying' 'forms' 'goes'\n",
            " 'hope' 'idea' 'larger' 'later' 'like' 'man' 'new' 'news' 'read' 'saw'\n",
            " 'scientist' 'study' 'tale' 'transportation' 'unique' 'yesterday']\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# Initialize the CountVectorizer\n",
        "vectorizer = CountVectorizer(\n",
        "    stop_words='english',\n",
        "    lowercase=True,\n",
        "    token_pattern=r\"(?u)\\b\\w\\w+\\b\"\n",
        ")\n",
        "\n",
        "corpus = [original_text]\n",
        "\n",
        "# Fit the vectorizer on your text data (i.e. corpus) to build the vocabulary\n",
        "vectorizer.fit(corpus)\n",
        "\n",
        "# Transform your text data into a BoW representation\n",
        "bow_representation = vectorizer.transform(corpus)\n",
        "\n",
        "# The BoW representation is now a sparse matrix containing the word counts\n",
        "# You can convert it to an array if you want to see it in a more readable format\n",
        "bow_array = bow_representation.toarray()\n",
        "\n",
        "# To see the feature names (words) corresponding to each column in the BoW array\n",
        "feature_names = vectorizer.get_feature_names_out()\n",
        "\n",
        "# The bow_array is your BoW representation and feature_names are the words in the vocabulary\n",
        "print(bow_array)\n",
        "print(feature_names)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d63e3746",
      "metadata": {
        "id": "d63e3746"
      },
      "source": [
        "## Cosine Similarity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "47dd71ad",
      "metadata": {
        "id": "47dd71ad"
      },
      "outputs": [],
      "source": [
        "!pip install numpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5dd3d514",
      "metadata": {
        "id": "5dd3d514",
        "outputId": "87c7fc13-3271-456c-fc6a-83251277ffc3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[1 2 0 1 1 0 1]\n",
            " [0 0 0 1 1 0 1]\n",
            " [1 0 1 1 0 1 0]]\n",
            "['big' 'cat' 'moon' 'small' 'table' 'tree' 'window']\n"
          ]
        }
      ],
      "source": [
        "t1 = \"The big cat is on the table and the small cat in the window \"\n",
        "t2 = \"The table and the window are small\"\n",
        "t3 = \"The moon and the small tree are big\"\n",
        "\n",
        "corpus = [t1, t2, t3]\n",
        "\n",
        "\n",
        "vectorizer.fit(corpus)\n",
        "bow_representation = vectorizer.transform(corpus)\n",
        "bow_array = bow_representation.toarray()\n",
        "feature_names = vectorizer.get_feature_names_out()\n",
        "print(bow_array)\n",
        "print(feature_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "55319aff",
      "metadata": {
        "id": "55319aff",
        "outputId": "9f37a325-0cf7-4f88-e33f-f0acbd804075"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[1.        , 0.61237244, 0.35355339],\n",
              "       [0.61237244, 1.        , 0.28867513],\n",
              "       [0.35355339, 0.28867513, 1.        ]])"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "\n",
        "# Convert the list of vectors to a numpy array\n",
        "vector_array = np.array(bow_array)\n",
        "\n",
        "# Calculate the cosine similarity between all pairs of vectors in the list\n",
        "# This will produce a similarity matrix where each element (i, j) is the cosine similarity\n",
        "# between the ith and jth vectors in the list\n",
        "cosine_similarities = cosine_similarity(vector_array)\n",
        "\n",
        "cosine_similarities\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "41b339d7",
      "metadata": {
        "id": "41b339d7"
      },
      "source": [
        "## Word2Vec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f118da7b",
      "metadata": {
        "id": "f118da7b"
      },
      "outputs": [],
      "source": [
        "!pip install gensim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cefddf5b",
      "metadata": {
        "id": "cefddf5b"
      },
      "outputs": [],
      "source": [
        "from gensim.models import Word2Vec\n",
        "\n",
        "# Normally, you would need a large corpus of sentences to train a Word2Vec model.\n",
        "\n",
        "# Let's create a simple corpus using the given words.\n",
        "# This is not ideal for training a Word2Vec model but is only for demonstration purposes.\n",
        "sentences = [filtered_tokens]  # In reality, you would need a much larger and varied corpus\n",
        "\n",
        "# Initialize and train the Word2Vec model\n",
        "model = Word2Vec(sentences=sentences, vector_size=5, window=5, min_count=1, workers=2)\n",
        "\n",
        "# Extract the Word2Vec embeddings for each word\n",
        "word_vectors = {token: model.wv[token] for token in filtered_tokens}\n",
        "\n",
        "# The word_vectors dictionary now contains the Word2Vec embeddings for the words\n",
        "print(word_vectors)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "16acb6fe",
      "metadata": {
        "id": "16acb6fe"
      },
      "source": [
        "## Glove"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0ff4e1b2",
      "metadata": {
        "id": "0ff4e1b2"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "\n",
        "# Load the spaCy model that includes GloVe vectors\n",
        "nlp = spacy.load('en_core_web_md')  # or 'en_core_web_lg' for larger GloVe vectors\n",
        "\n",
        "# Access vectors for each word using the loaded model\n",
        "glove_vectors = {token: nlp.vocab[token].vector for token in filtered_tokens}\n",
        "\n",
        "print(glove_vectors)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3a13179c",
      "metadata": {
        "id": "3a13179c"
      },
      "source": [
        "## Fasttext"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "05d9de33",
      "metadata": {
        "id": "05d9de33"
      },
      "outputs": [],
      "source": [
        "from gensim.models.fasttext import FastText as FT_gensim\n",
        "\n",
        "# Aseg√∫rate de actualizar esta ruta al lugar donde tienes el modelo FastText\n",
        "model_path = '/path/to/fasttext/model.bin'\n",
        "\n",
        "# Cargamos el modelo de FastText\n",
        "model = FT_gensim.load_fasttext_format(model_path)\n",
        "\n",
        "# Obtener los vectores FastText para cada palabra\n",
        "fasttext_vectors = {token: model.wv[token] for token in filtered_tokens}\n",
        "print(fasttext_vectors)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "88306416",
      "metadata": {
        "id": "88306416"
      },
      "source": [
        "## Sentence Transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "90403263",
      "metadata": {
        "id": "90403263"
      },
      "outputs": [],
      "source": [
        "!pip install -U sentence-transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "33a47d46",
      "metadata": {
        "id": "33a47d46"
      },
      "outputs": [],
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
        "\n",
        "# Sentences we want to encode. Example:\n",
        "sentence = [\"Yesterday, I couldn't believe my eyes: I saw a man carrying a bunch of colorful balloons flying over the city! It was like something out of a fairy tale. Later, I read in the news that he's a scientist who's experimenting with new forms of transportation. His 'flying' experiment was part of a larger study. I hope it goes well; it's such a unique idea! \"]\n",
        "\n",
        "# Sentences are encoded by calling model.encode()\n",
        "embedding = model.encode(sentence)\n",
        "print(embedding)"
      ]
    }
  ],
  "metadata": {
    "finalized": {
      "timestamp": 1705668643685,
      "trusted": true
    },
    "kernelspec": {
      "display_name": "venv-metal",
      "language": "python",
      "name": "venv-metal"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
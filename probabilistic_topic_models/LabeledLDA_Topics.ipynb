{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LabeledLDA-Topics.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMyPTF0rDYMJcTRGi8E/JhZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cbadenes/notebooks/blob/main/probabilistic_topic_models/LabeledLDA_Topics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use a Python implementation of Labeled-LDA based on Gibbs sampling\n",
        " from [JoeZJH](https://github.com/JoeZJH/Labeled-LDA-Python)"
      ],
      "metadata": {
        "id": "M_mMJJTO7e0z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UtF6fdDX7Y7o",
        "outputId": "14412758-57ba-4288-a99c-1d0625f1a128"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Labeled-LDA-Python'...\n",
            "remote: Enumerating objects: 175, done.\u001b[K\n",
            "remote: Counting objects: 100% (24/24), done.\u001b[K\n",
            "remote: Compressing objects: 100% (14/14), done.\u001b[K\n",
            "remote: Total 175 (delta 8), reused 24 (delta 8), pack-reused 151\u001b[K\n",
            "Receiving objects: 100% (175/175), 322.44 KiB | 17.91 MiB/s, done.\n",
            "Resolving deltas: 100% (69/69), done.\n",
            "total 44\n",
            "drwxr-xr-x 6 root root 4096 Feb 28 15:25 .\n",
            "drwxr-xr-x 1 root root 4096 Feb 28 15:25 ..\n",
            "drwxr-xr-x 2 root root 4096 Feb 28 15:25 assets\n",
            "drwxr-xr-x 2 root root 4096 Feb 28 15:25 example\n",
            "drwxr-xr-x 8 root root 4096 Feb 28 15:25 .git\n",
            "-rw-r--r-- 1 root root   47 Feb 28 15:25 .gitignore\n",
            "-rw-r--r-- 1 root root 1069 Feb 28 15:25 LICENSE\n",
            "drwxr-xr-x 2 root root 4096 Feb 28 15:25 model\n",
            "-rw-r--r-- 1 root root 5684 Feb 28 15:25 README.md\n",
            "-rw-r--r-- 1 root root   14 Feb 28 15:25 requirements.txt\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "!git clone https://github.com/JoeZJH/Labeled-LDA-Python\n",
        "os.chdir('Labeled-LDA-Python/')\n",
        "!ls -la"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initialize a Labeled Topic Model\n",
        "* `K`: the number of topics\n",
        "* `M`: the number of documents\n",
        "* `W`: the corpus, a list of terms list,\n",
        "              W[m] is the document vector, W[m][n] is the id of the term\n",
        "* `T`: the number of terms\n",
        "* `WN`: the number of all words in W\n",
        "* `LN`: the number of all original labels\n",
        "* `alpha`: doc-topics ratio\n",
        "* `eta`: topic-terms ratio"
      ],
      "metadata": {
        "id": "8SrLo7Lz9los"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import model.labeled_lda as llda\n",
        "\n",
        "# initialize data\n",
        "labeled_documents = [(\"example example example example example\"*10, [\"example\"]),\n",
        "                     (\"test llda model test llda model test llda model\"*10, [\"test\", \"llda_model\"]),\n",
        "                     (\"example test example test example test example test\"*10, [\"example\", \"test\"]),\n",
        "                     (\"good perfect good good perfect good good perfect good \"*10, [\"positive\"]),\n",
        "                     (\"bad bad down down bad bad down\"*10, [\"negative\"])]\n",
        "\n",
        "# new a Labeled LDA model\n",
        "# llda_model = llda.LldaModel(labeled_documents=labeled_documents, alpha_vector=\"50_div_K\", eta_vector=0.001)\n",
        "# llda_model = llda.LldaModel(labeled_documents=labeled_documents, alpha_vector=0.02, eta_vector=0.002)\n",
        "llda_model = llda.LldaModel(labeled_documents=labeled_documents, alpha_vector=0.01, eta_vector=0.001)\n",
        "print(llda_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H410Bl-I8DaN",
        "outputId": "88bd3380-96f1-452b-95a8-f64c04864159"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Labeled-LDA Model:\n",
            "\tK = 6\n",
            "\tM = 5\n",
            "\tT = 12\n",
            "\tWN = 344\n",
            "\tLN = 7\n",
            "\talpha = 0.01\n",
            "\teta = 0.001\n",
            "\tperplexity = 3.9683718068695697\n",
            "\t\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train "
      ],
      "metadata": {
        "id": "i79RC2SZ9pt6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# training\n",
        "# llda_model.training(iteration=10, log=True)\n",
        "while True:\n",
        "    print(\"iteration %s sampling...\" % (llda_model.iteration + 1))\n",
        "    llda_model.training(1)\n",
        "    print(\"after iteration: %s, perplexity: %s\" % (llda_model.iteration, llda_model.perplexity()))\n",
        "    print(\"delta beta: %s\" % llda_model.delta_beta)\n",
        "    if llda_model.is_convergent(method=\"beta\", delta=0.01):\n",
        "        break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D6qPPIMQ8Jv8",
        "outputId": "bb4c258a-cb84-421c-fba5-3797125ba22f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iteration 1 sampling...\n",
            "gibbs sample count:  344\n",
            "after iteration: 1, perplexity: 2.948204518307306\n",
            "delta beta: 1.829836168167582\n",
            "iteration 2 sampling...\n",
            "gibbs sample count:  344\n",
            "after iteration: 2, perplexity: 2.6239852397791985\n",
            "delta beta: 1.6409206682875814\n",
            "iteration 3 sampling...\n",
            "gibbs sample count:  344\n",
            "after iteration: 3, perplexity: 2.573645211454954\n",
            "delta beta: 1.2799773845474132\n",
            "iteration 4 sampling...\n",
            "gibbs sample count:  344\n",
            "after iteration: 4, perplexity: 2.576271045875313\n",
            "delta beta: 0.11655324642799364\n",
            "iteration 5 sampling...\n",
            "gibbs sample count:  344\n",
            "after iteration: 5, perplexity: 2.576271045875313\n",
            "delta beta: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Update an existing model with new documents"
      ],
      "metadata": {
        "id": "qveDYzYd9zU9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# update\n",
        "print(\"before updating: \", llda_model)\n",
        "update_labeled_documents = [(\"new example test example test example test example test\", [\"example\", \"test\"])]\n",
        "llda_model.update(labeled_documents=update_labeled_documents)\n",
        "print(\"after updating: \", llda_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qYaIEeEU8OQN",
        "outputId": "8fe89c48-9bb7-47c4-ea88-21d17ac7b7a5"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "before updating:  \n",
            "Labeled-LDA Model:\n",
            "\tK = 6\n",
            "\tM = 5\n",
            "\tT = 12\n",
            "\tWN = 344\n",
            "\tLN = 7\n",
            "\talpha = 0.01\n",
            "\teta = 0.001\n",
            "\tperplexity = 2.576271045875313\n",
            "\t\n",
            "after updating:  \n",
            "Labeled-LDA Model:\n",
            "\tK = 6\n",
            "\tM = 6\n",
            "\tT = 13\n",
            "\tWN = 353\n",
            "\tLN = 11\n",
            "\talpha = 0.01\n",
            "\teta = 0.001\n",
            "\tperplexity = 2.683861643881013\n",
            "\t\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train again\n",
        "# llda_model.training(iteration=10, log=True)\n",
        "while True:\n",
        "    print(\"iteration %s sampling...\" % (llda_model.iteration + 1))\n",
        "    llda_model.training(1)\n",
        "    print(\"after iteration: %s, perplexity: %s\" % (llda_model.iteration, llda_model.perplexity()))\n",
        "    print(\"delta beta: %s\" % llda_model.delta_beta)\n",
        "    if llda_model.is_convergent(method=\"beta\", delta=0.01):\n",
        "        break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "URo7ddNS8S-l",
        "outputId": "0c7af0ab-8b6d-43e9-c838-4d56f4c751ef"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iteration 6 sampling...\n",
            "gibbs sample count:  353\n",
            "after iteration: 6, perplexity: 2.619759333193657\n",
            "delta beta: 0.953266522426173\n",
            "iteration 7 sampling...\n",
            "gibbs sample count:  353\n",
            "after iteration: 7, perplexity: 2.6014164700095175\n",
            "delta beta: 1.166284331758653\n",
            "iteration 8 sampling...\n",
            "gibbs sample count:  353\n",
            "after iteration: 8, perplexity: 2.5969196211475443\n",
            "delta beta: 0.2049851733233044\n",
            "iteration 9 sampling...\n",
            "gibbs sample count:  353\n",
            "after iteration: 9, perplexity: 2.595314188042728\n",
            "delta beta: 0.028529499507375995\n",
            "iteration 10 sampling...\n",
            "gibbs sample count:  353\n",
            "after iteration: 10, perplexity: 2.5969196211475443\n",
            "delta beta: 0.028529499507375995\n",
            "iteration 11 sampling...\n",
            "gibbs sample count:  353\n",
            "after iteration: 11, perplexity: 2.5961458918908167\n",
            "delta beta: 0.10507898616959299\n",
            "iteration 12 sampling...\n",
            "gibbs sample count:  353\n",
            "after iteration: 12, perplexity: 2.598830102713859\n",
            "delta beta: 0.0553038760279235\n",
            "iteration 13 sampling...\n",
            "gibbs sample count:  353\n",
            "after iteration: 13, perplexity: 2.6075486181449783\n",
            "delta beta: 0.5449565886192309\n",
            "iteration 14 sampling...\n",
            "gibbs sample count:  353\n",
            "after iteration: 14, perplexity: 2.617918869850826\n",
            "delta beta: 0.9971737056566299\n",
            "iteration 15 sampling...\n",
            "gibbs sample count:  353\n",
            "after iteration: 15, perplexity: 2.6173893786598152\n",
            "delta beta: 0.07601830989133937\n",
            "iteration 16 sampling...\n",
            "gibbs sample count:  353\n",
            "after iteration: 16, perplexity: 2.617918869850826\n",
            "delta beta: 0.07601830989133937\n",
            "iteration 17 sampling...\n",
            "gibbs sample count:  353\n",
            "after iteration: 17, perplexity: 2.6183418769298408\n",
            "delta beta: 0.026110164487703362\n",
            "iteration 18 sampling...\n",
            "gibbs sample count:  353\n",
            "after iteration: 18, perplexity: 2.6174669784924287\n",
            "delta beta: 0.07714704737268693\n",
            "iteration 19 sampling...\n",
            "gibbs sample count:  353\n",
            "after iteration: 19, perplexity: 2.634244044065968\n",
            "delta beta: 1.852221498506323\n",
            "iteration 20 sampling...\n",
            "gibbs sample count:  353\n",
            "after iteration: 20, perplexity: 2.6178200231805584\n",
            "delta beta: 1.9977981605759576\n",
            "iteration 21 sampling...\n",
            "gibbs sample count:  353\n",
            "after iteration: 21, perplexity: 2.618331977219667\n",
            "delta beta: 0.06984511383291583\n",
            "iteration 22 sampling...\n",
            "gibbs sample count:  353\n",
            "after iteration: 22, perplexity: 2.618495979727599\n",
            "delta beta: 0.02302094423029294\n",
            "iteration 23 sampling...\n",
            "gibbs sample count:  353\n",
            "after iteration: 23, perplexity: 2.6186463603523835\n",
            "delta beta: 0.02293598332496794\n",
            "iteration 24 sampling...\n",
            "gibbs sample count:  353\n",
            "after iteration: 24, perplexity: 2.6318560921784493\n",
            "delta beta: 1.9673653900038068\n",
            "iteration 25 sampling...\n",
            "gibbs sample count:  353\n",
            "after iteration: 25, perplexity: 2.609748694236845\n",
            "delta beta: 1.912547647262393\n",
            "iteration 26 sampling...\n",
            "gibbs sample count:  353\n",
            "after iteration: 26, perplexity: 2.6260707086737654\n",
            "delta beta: 1.9561529335458365\n",
            "iteration 27 sampling...\n",
            "gibbs sample count:  353\n",
            "after iteration: 27, perplexity: 2.5957622815735513\n",
            "delta beta: 2.015674236011803\n",
            "iteration 28 sampling...\n",
            "gibbs sample count:  353\n",
            "after iteration: 28, perplexity: 2.604706970584536\n",
            "delta beta: 0.16678026187207703\n",
            "iteration 29 sampling...\n",
            "gibbs sample count:  353\n",
            "after iteration: 29, perplexity: 2.621687930583561\n",
            "delta beta: 1.8527624299133305\n",
            "iteration 30 sampling...\n",
            "gibbs sample count:  353\n",
            "after iteration: 30, perplexity: 2.6061752455842027\n",
            "delta beta: 1.9045790684527433\n",
            "iteration 31 sampling...\n",
            "gibbs sample count:  353\n",
            "after iteration: 31, perplexity: 2.5940775012533166\n",
            "delta beta: 0.2483742471099061\n",
            "iteration 32 sampling...\n",
            "gibbs sample count:  353\n",
            "after iteration: 32, perplexity: 2.5982884676513076\n",
            "delta beta: 0.0875027445354913\n",
            "iteration 33 sampling...\n",
            "gibbs sample count:  353\n",
            "after iteration: 33, perplexity: 2.5990739998167807\n",
            "delta beta: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Explore Topics"
      ],
      "metadata": {
        "id": "YSfhyVy5_G-E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for topic in llda_model.topic_vocabulary.keys():\n",
        "  print(\"Topic '\",topic,\"' :\")\n",
        "  for term in llda_model.top_terms_of_topic(topic,5):\n",
        "    print(\"\\t-\",term)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m5I061wC_IRc",
        "outputId": "8a6c5228-1267-4193-ed7a-85b915b408c6"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Topic ' common_topic ' :\n",
            "\t- ('new', 0.9881539980256663)\n",
            "\t- ('exampleexample', 0.000987166831194472)\n",
            "\t- ('perfect', 0.000987166831194472)\n",
            "\t- ('down', 0.000987166831194472)\n",
            "\t- ('testexample', 0.000987166831194472)\n",
            "Topic ' positive ' :\n",
            "\t- ('good', 0.6665814937842309)\n",
            "\t- ('perfect', 0.33329630164531776)\n",
            "\t- ('exampleexample', 1.1109506404630438e-05)\n",
            "\t- ('down', 1.1109506404630438e-05)\n",
            "\t- ('testexample', 1.1109506404630438e-05)\n",
            "Topic ' llda_model ' :\n",
            "\t- ('llda', 0.49990835319014215)\n",
            "\t- ('model', 0.3499408461500009)\n",
            "\t- ('modeltest', 0.1499841700964791)\n",
            "\t- ('exampleexample', 1.666305633779348e-05)\n",
            "\t- ('perfect', 1.666305633779348e-05)\n",
            "Topic ' negative ' :\n",
            "\t- ('bad', 0.5081048301181715)\n",
            "\t- ('down', 0.3442053332896268)\n",
            "\t- ('downbad', 0.14752593709537312)\n",
            "\t- ('exampleexample', 1.6389949682854473e-05)\n",
            "\t- ('perfect', 1.6389949682854473e-05)\n",
            "Topic ' example ' :\n",
            "\t- ('example', 0.8674959198976664)\n",
            "\t- ('exampleexample', 0.1323423463161454)\n",
            "\t- ('perfect', 1.4703071471630419e-05)\n",
            "\t- ('down', 1.4703071471630419e-05)\n",
            "\t- ('testexample', 1.4703071471630419e-05)\n",
            "Topic ' test ' :\n",
            "\t- ('test', 0.7670003971895415)\n",
            "\t- ('testexample', 0.12327941599441193)\n",
            "\t- ('example', 0.10958322490515386)\n",
            "\t- ('exampleexample', 1.3696191089258077e-05)\n",
            "\t- ('perfect', 1.3696191089258077e-05)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inference\n",
        "\n",
        "* `document`: some sentence like \"this is a method for inference\"\n",
        "* `times`: the number of samples of the target distribution (one whole iteration(sample for all words) generates a sample)\n",
        "* `iteration`: the times of iteration until Markov chain converges"
      ],
      "metadata": {
        "id": "HNYF5hh6-AaM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# inference\n",
        "# note: the result topics may be different for difference training, because gibbs sampling is a random algorithm\n",
        "document = \"example llda model example example good perfect good perfect good perfect\" * 100\n",
        "\n",
        "topics = llda_model.inference(document=document, iteration=100, times=10)\n",
        "print(topics)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UgN6hkkQ8V2q",
        "outputId": "336dc6e0-1e7f-4829-a0f7-24c83a10a5d8"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('positive', 0.5554065139791144), ('common_topic', 0.4445491430725229), ('llda_model', 1.1085737090659159e-05), ('negative', 1.1085737090659159e-05), ('example', 1.1085737090659159e-05), ('test', 1.1085737090659159e-05)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation"
      ],
      "metadata": {
        "id": "d1mzPnwn-DxC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# perplexity\n",
        "# calculate perplexity on test data\n",
        "perplexity = llda_model.perplexity(documents=[\"example example example example example\",\n",
        "                                              \"test llda model test llda model test llda model\",\n",
        "                                              \"example test example test example test example test\",\n",
        "                                              \"good perfect good good perfect good good perfect good\",\n",
        "                                              \"bad bad down down bad bad down\"],\n",
        "                                   iteration=30,\n",
        "                                   times=10)\n",
        "print(\"perplexity on test data: %s\" % perplexity)\n",
        "# calculate perplexity on training data\n",
        "print(\"perplexity on training data: %s\" % llda_model.perplexity())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QLG4UbhH8c3o",
        "outputId": "0878dd87-9074-4f65-a8f9-2c7b9de5d67f"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "perplexity on test data: 5.2135218369149285\n",
            "perplexity on training data: 2.5990739998167807\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Save Model"
      ],
      "metadata": {
        "id": "jIDHBja1-GTT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# save to disk\n",
        "save_model_dir = \"data/model\"\n",
        "# llda_model.save_model_to_dir(save_model_dir, save_derivative_properties=True)\n",
        "llda_model.save_model_to_dir(save_model_dir)"
      ],
      "metadata": {
        "id": "IMvQz-KK8gCg"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Model"
      ],
      "metadata": {
        "id": "t6xZdbRA-H0J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load from disk\n",
        "llda_model_new = llda.LldaModel()\n",
        "llda_model_new.load_model_from_dir(save_model_dir, load_derivative_properties=False)\n",
        "print(\"llda_model_new\", llda_model_new)\n",
        "print(\"llda_model\", llda_model)\n",
        "print(\"Top-5 terms of topic 'negative': \", llda_model.top_terms_of_topic(\"negative\", 5, False))\n",
        "print(\"Doc-Topic Matrix: \\n\", llda_model.theta)\n",
        "print(\"Topic-Term Matrix: \\n\", llda_model.beta)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qDQAlPOu8jfE",
        "outputId": "64682b17-67a7-4163-e1f5-2d3ca122b8cb"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "llda_model_new \n",
            "Labeled-LDA Model:\n",
            "\tK = 6\n",
            "\tM = 6\n",
            "\tT = 13\n",
            "\tWN = 353\n",
            "\tLN = 11\n",
            "\talpha = 0.01\n",
            "\teta = 0.001\n",
            "\tperplexity = 2.5742566681649377\n",
            "\t\n",
            "llda_model \n",
            "Labeled-LDA Model:\n",
            "\tK = 6\n",
            "\tM = 6\n",
            "\tT = 13\n",
            "\tWN = 353\n",
            "\tLN = 11\n",
            "\talpha = 0.01\n",
            "\teta = 0.001\n",
            "\tperplexity = 2.5742566681649377\n",
            "\t\n",
            "Top-5 terms of topic 'negative':  ['bad', 'down', 'downbad', 'exampleexample', 'perfect']\n",
            "Doc-Topic Matrix: \n",
            " [[0.         0.         0.         0.         1.         0.        ]\n",
            " [0.         0.         1.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.43661972 0.56338028]\n",
            " [0.87777778 0.12222222 0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         1.         0.         0.        ]\n",
            " [0.00110742 0.         0.         0.         0.4440753  0.55481728]]\n",
            "Topic-Term Matrix: \n",
            " [[1.26561452e-05 3.79697012e-01 1.26561452e-05 1.26561452e-05\n",
            "  1.26561452e-05 6.20163771e-01 1.26561452e-05 1.26561452e-05\n",
            "  1.26561452e-05 1.26561452e-05 1.26561452e-05 1.26561452e-05\n",
            "  1.26561452e-05]\n",
            " [9.08017797e-05 9.08017797e-05 9.08017797e-05 9.08017797e-05\n",
            "  9.08017797e-05 9.98910379e-01 9.08017797e-05 9.08017797e-05\n",
            "  9.08017797e-05 9.08017797e-05 9.08017797e-05 9.08017797e-05\n",
            "  9.08017797e-05]\n",
            " [1.23436979e-05 1.23436979e-05 1.23436979e-05 1.23436979e-05\n",
            "  1.11105625e-01 1.23436979e-05 1.23436979e-05 1.23436979e-05\n",
            "  2.59230000e-01 1.23436979e-05 3.70323281e-01 2.59230000e-01\n",
            "  1.23436979e-05]\n",
            " [1.63899497e-05 1.63899497e-05 3.44205333e-01 1.63899497e-05\n",
            "  1.63899497e-05 1.63899497e-05 1.47525937e-01 1.63899497e-05\n",
            "  1.63899497e-05 5.08104830e-01 1.63899497e-05 1.63899497e-05\n",
            "  1.63899497e-05]\n",
            " [1.18413956e-01 1.31556444e-05 1.31556444e-05 1.31556444e-05\n",
            "  1.31556444e-05 1.31556444e-05 1.31556444e-05 8.81441332e-01\n",
            "  1.31556444e-05 1.31556444e-05 1.31556444e-05 1.31556444e-05\n",
            "  1.31556444e-05]\n",
            " [2.22158043e-05 2.22158043e-05 2.22158043e-05 1.99964455e-01\n",
            "  2.22158043e-05 2.22158043e-05 2.22158043e-05 2.22158043e-05\n",
            "  7.77575367e-01 2.22158043e-05 2.22158043e-05 2.22158043e-05\n",
            "  2.22380201e-02]]\n"
          ]
        }
      ]
    }
  ]
}